# Topics

- Brownian bridge on cone surface
- Wrapped normal distribution

---

### From 2025-04-28 to 2025-05-22

Below I've worked out the integral for the variance term in the multivariate normal distribution which tells us the probability of going from one sample location to another. This follows the same principles as Matt and Graham's **SpaceTrees** but now where the dispersal rate deterministically grows as you move back in time (see *devlog20250418* for more details).

$\int_{x}^{y}\sigma_t^2dt = \int_{x}^{y}(\frac{\sigma_0r_0}{r_0-vt})^2dt = \frac{\sigma_0^2r_0^2(y-x)}{(r_0-vx)(r_0-vy)}$


$(\int_{x}^{y}\sigma_t^2dt)+(\int_{z}^{y}\sigma_t^2dt) = \frac{\sigma_0^2r_0^2(y-x)}{(r_0-vx)(r_0-vy)} + \frac{\sigma_0^2r_0^2(y-z)}{(r_0-vz)(r_0-vy)} = \frac{\sigma_0^2r_0^2}{r_0-vy}(\frac{y-x}{r_0-vx}+\frac{y-z}{r_0-vz})$

Altogether, $X_x \sim Normal(x_z, \frac{\sigma_0^2r_0^2}{r_0-vy}(\frac{y-x}{r_0-vx}+\frac{y-z}{r_0-vz}))$ where $x$ is the time of sample 0, $y$ is the TMRCA between the samples, and $z$ is the time of sample 1.

Graham pointed out that as $vy$ approaches $r_0$ (in English, as you go back in time and the ring size shrinks to a point), the variance in $X_x$ goes to infinity; this may lead to a problem when two samples coalesce deep in the past. I initially thought that first modelling everything using the multivariate normal before trying to tackle the wrapped multivariate normal would make things easier. But as the variance of the normal distribution increases to infinity, its probability distribution function (pdf) gets flatter and lower until its essentially 0 everywhere. Conversely, as the variance of the wrapped normal distribution increases, the pdf converges to a uniform distribution bound on the length of the circumference of the ring. I think that this difference between the distributions is the key to working with two samples that coalesce deep in the past, when one's location should be essentially uninformative about the others. 